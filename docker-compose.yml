services:
  main-app:
    platform: linux/amd64
    build:
      context: .
      dockerfile: apps/main/Dockerfile
      tags:
        - artbrushlens-main-app:latest
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_GRAPHQL_URL=http://localhost:4000/graphql
      - NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
    volumes:
      - ./apps/main:/app/apps/main
      - /app/node_modules
    depends_on:
      - server

  admin-app:
    platform: linux/amd64
    build:
      context: .
      dockerfile: apps/admin/Dockerfile
      tags:
        - artbrushlens-admin-app:latest
    ports:
      - "3001:3001" # Host port 3001 â†’ Container port 3001
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_GRAPHQL_URL=http://localhost:4000/graphql
      - NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
      - NEXT_PUBLIC_AUTH0_DOMAIN=your-auth0-domain
      - NEXT_PUBLIC_AUTH0_CLIENT_ID=your-auth0-client-id
    volumes:
      - ./apps/admin:/app/apps/admin
      - /app/node_modules
    depends_on:
      - server

  server:
    platform: linux/amd64
    build:
      context: . 
      dockerfile: apps/server/Dockerfile
      tags:
        - local-ai/localai:latest
        - artbrushlens-server:latest
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=development
      - SUPABASE_URL=http://localhost:54321
      - SUPABASE_SERVICE_KEY=your-service-key
      - OPENAI_API_KEY=your-openai-key
      - LOCAL_AI_URL=http://localhost:8080
      - USE_LOCAL_AI=true
      - MET_API_URL=https://collectionapi.metmuseum.org/public/collection/v1
    volumes:
      - ./apps/server:/app/apps/server
      - /app/node_modules

  local-ai:
    image: localai/localai:latest
    platform: linux/amd64
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models
    environment:
      - MODELS_PATH=/models